{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLznt1l_wH8z"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VchSpDOkzUdG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, BatchNormalization, Input, Reshape, Flatten, Conv2DTranspose, MaxPooling2D, UpSampling2D, Add\n",
        "from tensorflow.keras.layers import LeakyReLU, Lambda, ReLU, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from functools import partial\n",
        "import re\n",
        "import numpy as np\n",
        "import math, os\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detecting TPU\n",
        "\n",
        "Detect TPU, if it is available use it! \n",
        "Please, note that use TPU requires the TFRecord data in Google Cloud Storage"
      ],
      "metadata": {
        "id": "VB8V-BLSPRS5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x7MoCib1rgh"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu is not None:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy() \n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training parameters"
      ],
      "metadata": {
        "id": "Y6gr8cZhT1vj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ui7en7z0cPD"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "  'MSE_LOSS_LAMBDA': 0.01,  \n",
        "  'PERP_LOSS_LAMBDA': 1,\n",
        "  #'PERP_LOSS_LAMBDA': 1e-4,\n",
        "  'perceptual_layers' : [5,8,13,18],\n",
        "    \n",
        "  'USE_CUTOUT' : True,\n",
        "\n",
        "  'EPOCHS' : 1000,\n",
        "\n",
        "  'BATCH_SIZE' : 16 * strategy.num_replicas_in_sync if strategy.num_replicas_in_sync > 1 else 64,\n",
        "  'RECORD_SIZE' : (256+20,256+20,3),\n",
        "  'IMAGE_SIZE' : (256,256,3),\n",
        "  'LATENT_DIM' : 500,\n",
        "\n",
        "  'LR_START' : 1e-5,\n",
        "  'LR_MIN' : 1e-5,\n",
        "  'LR_MAX' : 9e-4 * strategy.num_replicas_in_sync,\n",
        "  'LR_RAMPUP_EPOCHS' : 3,\n",
        "  'LR_SUSTAIN_EPOCHS' : 0,\n",
        "  'N_CYCLES' : .5,\n",
        "\n",
        "  'SEED' : 100,\n",
        "\n",
        "  'use_bn' : True,\n",
        "  'use_bn_dconv' : True,\n",
        "  'lrelu_slop' : 0.2,\n",
        "\n",
        "  'USE_TFRECORD' : True\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2o-LLCnUwTP9"
      },
      "outputs": [],
      "source": [
        "grids = grid_list = [ [3,1], [4,1], [2,2], [3,2], [2,3], [4,3] ]\n",
        "\n",
        "BASE_OUTPUT = '/content/gdrive/MyDrive/pcbs_cae/'\n",
        "\n",
        "## The dataset is available in the following Google Storage. Note that is necessary store the data in GS to use TPUs\n",
        "if params['USE_TFRECORD']:\n",
        "  BASE_DATA = 'gs://mpi_pcb/'\n",
        "else:\n",
        "  BASE_DATA = '/content/gdrive/MyDrive/mpi_pcbs/'\n",
        "\n",
        "if not os.path.exists(BASE_OUTPUT):\n",
        "  os.makedirs(BASE_OUTPUT)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cutout function"
      ],
      "metadata": {
        "id": "qo-T4nzBT6Ux"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQZKq-R1xOcL"
      },
      "outputs": [],
      "source": [
        "def random_cutout(image, label, height, width, channels=3, min_mask_size=(10, 10), max_mask_size=(80, 80), k=1):\n",
        "  assert height > min_mask_size[0]\n",
        "  assert width > min_mask_size[1]\n",
        "  assert height > max_mask_size[0]\n",
        "  assert width > max_mask_size[1]\n",
        "\n",
        "    \n",
        "  for i in range(k):\n",
        "    mask_height = tf.random.uniform(shape=[], minval=min_mask_size[0], maxval=max_mask_size[0], dtype=tf.int32)\n",
        "    mask_width = tf.random.uniform(shape=[], minval=min_mask_size[1], maxval=max_mask_size[1], dtype=tf.int32)\n",
        "\n",
        "    pad_h = height - mask_height\n",
        "    pad_top = tf.random.uniform(shape=[], minval=0, maxval=pad_h, dtype=tf.int32)\n",
        "    pad_bottom = pad_h - pad_top\n",
        "\n",
        "    pad_w = width - mask_width\n",
        "    pad_left = tf.random.uniform(shape=[], minval=0, maxval=pad_w, dtype=tf.int32)\n",
        "    pad_right = pad_w - pad_left\n",
        "\n",
        "    cutout_area = tf.zeros(shape=[mask_height, mask_width, channels], dtype=tf.uint8)\n",
        "    cutout_mask = tf.pad([cutout_area], [[0,0],[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\n",
        "    cutout_mask = tf.squeeze(cutout_mask, axis=0)\n",
        "    image = tf.multiply(tf.cast(image, tf.float32), tf.cast(cutout_mask, tf.float32))\n",
        "        \n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset functions"
      ],
      "metadata": {
        "id": "rY0zqPuUUHhY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUG3EIImdXkA"
      },
      "outputs": [],
      "source": [
        "def decode_image(image):\n",
        "  image = tf.image.decode_jpeg( image, channels=params['RECORD_SIZE'][2] )\n",
        "  image = tf.cast(image, tf.float32) / 255.0\n",
        "\n",
        "  image = tf.reshape(image, [*params['RECORD_SIZE']])\n",
        "  return image\n",
        "\n",
        "def read_tfrecord(example):\n",
        "  feature = { \"image\" : tf.io.FixedLenFeature([], tf.string)\n",
        "              ,\"image_name\" : tf.io.FixedLenFeature([], tf.string) \n",
        "              }\n",
        "\n",
        "  example = tf.io.parse_single_example(example, feature)\n",
        "  image = decode_image(example['image'])\n",
        "  return image\n",
        "\n",
        "def read_image(img_path):\n",
        "  img = tf.io.read_file(img_path)\n",
        "  img = tf.image.decode_image(img, channels=3)\n",
        "  img = tf.cast(img, tf.float32) / 255.0\n",
        "\n",
        "  return img\n",
        "\n",
        "def load_dataset(filenames, use_tfrecord=True, ordered=False):\n",
        "  ignore_order = tf.data.Options()\n",
        "  if not ordered:\n",
        "    ignore_order.experimental_deterministic = False\n",
        "\n",
        "  if use_tfrecord:\n",
        "    print(\"Reading from tfrecord!\")\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "    dataset = dataset.with_options(ignore_order)  \n",
        "    dataset = dataset.map(partial(read_tfrecord), num_parallel_calls=AUTO)\n",
        "  else:\n",
        "    print(\"Reading from file list!\")\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
        "    dataset = dataset.map(read_image, num_parallel_calls=AUTO)\n",
        "\n",
        "  return dataset\n",
        "\n",
        "def create_label(image):\n",
        "  image = tf.image.random_crop(image, [*params['IMAGE_SIZE']] )\n",
        "  return image, image\n",
        "\n",
        "def get_center_crop(image):\n",
        "  return tf.image.crop_to_bounding_box(image, 10, 10, 256, 256)\n",
        "\n",
        "def get_train_dataset(filenames, use_tfrecord=True):\n",
        "  dataset = load_dataset(filenames, use_tfrecord=use_tfrecord)\n",
        "  \n",
        "  dataset = dataset.map(lambda image: create_label(image), num_parallel_calls=AUTO )\n",
        "  dataset = dataset.map(lambda image, label: random_cutout(image, label, params['IMAGE_SIZE'][0], params['IMAGE_SIZE'][1], k=tf.random.uniform([],0,15, dtype=tf.int32)), num_parallel_calls=AUTO )\n",
        "\n",
        "  dataset = dataset.repeat()\n",
        "  dataset = dataset.shuffle(2048, seed=params['SEED'])\n",
        "  dataset = dataset.batch(params['BATCH_SIZE'])\n",
        "  dataset = dataset.prefetch(AUTO)\n",
        "  \n",
        "  return dataset\n",
        "\n",
        "def get_validation_dataset(filenames, use_tfrecord=True):\n",
        "  dataset = load_dataset(filenames, use_tfrecord=use_tfrecord)\n",
        "  dataset = dataset.map(lambda image: create_label(image), num_parallel_calls=AUTO )\n",
        "\n",
        "  dataset = dataset.batch(params['BATCH_SIZE'])\n",
        "  dataset = dataset.cache()\n",
        "  dataset = dataset.prefetch(AUTO)\n",
        "  \n",
        "  return dataset\n",
        "\n",
        "def get_test_dataset(filenames, use_tfrecord=True):\n",
        "  dataset = load_dataset(filenames, use_tfrecord=use_tfrecord)\n",
        "  dataset = dataset.shuffle(2048, seed=params['SEED'])\n",
        "  dataset = dataset.batch(params['BATCH_SIZE'])\n",
        "  dataset = dataset.map(lambda image: get_center_crop(image), num_parallel_calls=AUTO )\n",
        "  dataset = dataset.cache()\n",
        "  dataset = dataset.prefetch(AUTO)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning rate decay function"
      ],
      "metadata": {
        "id": "L2Gc8QnXUKk6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAf8iPq7xrq9"
      },
      "outputs": [],
      "source": [
        "def lrfn(epoch):\n",
        "  if epoch < LR_RAMPUP_EPOCHS:\n",
        "    lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "  elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "    lr = LR_MAX\n",
        "  else:\n",
        "    progress = (epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) / (EPOCHS - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)\n",
        "    lr = LR_MAX * (0.5 * (1.0 + tf.math.cos(math.pi * N_CYCLES * 2.0 * progress)))\n",
        "    if LR_MIN is not None:\n",
        "      lr = tf.math.maximum(LR_MIN, lr)\n",
        "            \n",
        "  return lr\n",
        "  \n",
        "LR_START = params['LR_START']\n",
        "LR_MIN = params['LR_MIN']\n",
        "LR_MAX = params['LR_MAX']\n",
        "LR_RAMPUP_EPOCHS = params['LR_RAMPUP_EPOCHS']\n",
        "LR_SUSTAIN_EPOCHS = params['LR_SUSTAIN_EPOCHS']\n",
        "N_CYCLES = params['N_CYCLES']\n",
        "EPOCHS = params['EPOCHS']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CAE architecture definition"
      ],
      "metadata": {
        "id": "V7L12eNgUNy4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6ZI9p22nSXH"
      },
      "outputs": [],
      "source": [
        "def conv_block(x, filters=16, kernel=5, stride=2, transpose=False, leaky=True, slope=0.2, padding='same', bn=False, bias=True, only_conv=False):\n",
        "  conv = Conv2DTranspose if transpose else Conv2D\n",
        "  activation = LeakyReLU(slope) if leaky else ReLU()\n",
        "  \n",
        "  x = conv(filters=filters, kernel_size=(kernel,kernel), strides=stride, padding=padding, use_bias=bias)(x)\n",
        "  if not only_conv:\n",
        "    if bn:\n",
        "      x = BatchNormalization()(x)\n",
        "    x = activation(x)\n",
        "  \n",
        "  return x\n",
        "\n",
        "def get_cae():\n",
        "  with strategy.scope():\n",
        "    n_leves_enc = 7\n",
        "    n_dense = int(params['IMAGE_SIZE'][0]/(2**n_leves_enc))\n",
        "\n",
        "    inputs = Input(shape=params['IMAGE_SIZE'], name='encoder_input')\n",
        "    conv1 = conv_block(inputs, 32, bn=params['use_bn'], slope=params['lrelu_slop'])\n",
        "    conv2 = conv_block(conv1, 64, bn=params['use_bn'], slope=params['lrelu_slop'])  \n",
        "    conv3 = conv_block(conv2, 128, bn=params['use_bn'], slope=params['lrelu_slop'])  \n",
        "    conv4 = conv_block(conv3, 128, bn=params['use_bn'], slope=params['lrelu_slop'])   \n",
        "    conv5 = conv_block(conv4, 256, bn=params['use_bn'], slope=params['lrelu_slop'])   \n",
        "    conv6 = conv_block(conv5, 256, bn=params['use_bn'], slope=params['lrelu_slop'])  \n",
        "    conv7 = conv_block(conv6, 256, bn=params['use_bn'], slope=params['lrelu_slop']) \n",
        "\n",
        "    conv7_flat = Flatten()(conv7)\n",
        "    fc1 = Dense(units=(n_dense*n_dense*256))(conv7_flat)\n",
        "    if params['use_bn']:\n",
        "      fc1 = BatchNormalization()(fc1)\n",
        "    fc1 = LeakyReLU(alpha=params['lrelu_slop'])(fc1)\n",
        "\n",
        "    fc1 = Dense(units=params['LATENT_DIM'])(fc1)\n",
        "    fc1 = LeakyReLU(alpha=params['lrelu_slop'])(fc1)\n",
        "\n",
        "    fc2 = Dense(units=(n_dense*n_dense*256))(fc1)\n",
        "    if params['use_bn']:\n",
        "      fc2 = BatchNormalization()(fc2)\n",
        "    fc2 = LeakyReLU(alpha=params['lrelu_slop'])(fc2)\n",
        "    \n",
        "    z_mat = Reshape((n_dense,n_dense,256))(fc2)\n",
        "    dconv0 = conv_block(z_mat, 256, transpose=True, bn=params['use_bn_dconv'], slope=params['lrelu_slop'])\n",
        "    dconv1 = conv_block(dconv0, 256, transpose=True, bn=params['use_bn_dconv'], slope=params['lrelu_slop'])\n",
        "    dconv2 = conv_block(dconv1, 128, transpose=True, bn=params['use_bn_dconv'], slope=params['lrelu_slop'])\n",
        "    dconv3 = conv_block(dconv2, 128, transpose=True, bn=params['use_bn_dconv'], slope=params['lrelu_slop'])\n",
        "    dconv4 = conv_block(dconv3, 64, transpose=True, bn=params['use_bn_dconv'], slope=params['lrelu_slop'])\n",
        "    dconv5 = conv_block(dconv4, 32, transpose=True, bn=params['use_bn_dconv'], slope=params['lrelu_slop'])\n",
        "    \n",
        "\n",
        "    dconv6 = Conv2DTranspose(filters=params['IMAGE_SIZE'][2], kernel_size=(5,5), strides=2, padding='same', \n",
        "        use_bias=True, activation='sigmoid')(dconv5)\n",
        "\n",
        "    ae_model = Model(inputs, dconv6, name=\"ae\")\n",
        "    #ae_model.summary()\n",
        "  return ae_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MSE + Perceptual loss"
      ],
      "metadata": {
        "id": "YxXo1_J_UTrp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioiebkB7rxpe"
      },
      "outputs": [],
      "source": [
        "def init_perceptual_loss(perp_layers):\n",
        "  perp_model = tf.keras.applications.VGG19(input_shape=(224,224,3))\n",
        "  modelOutputs = [perp_model.layers[i].output for i in perp_layers]\n",
        "  return Model(perp_model.inputs, modelOutputs)\n",
        "\n",
        "class MSE_Perceptual(tf.keras.losses.Loss):\n",
        "  def __init__(self, perc_layers, lambda_mse, lambda_perc):\n",
        "    super(MSE_Perceptual, self).__init__()\n",
        "    self.perc_layers = perc_layers\n",
        "    self.lambda_mse = lambda_mse\n",
        "    self.lambda_perc = lambda_perc\n",
        "    with strategy.scope():\n",
        "      self.perc_model = init_perceptual_loss(self.perc_layers)\n",
        "      self.loss_fn = tf.keras.losses.mean_squared_error\n",
        "\n",
        "  def call(self, y_true, y_pred):\n",
        "    mse_loss = tf.reduce_mean( tf.square( tf.math.pow(y_pred,2) - tf.math.pow(y_true,2) ) )\n",
        "\n",
        "    y_true_reshape = tf.image.resize(y_true, (224, 224))\n",
        "    y_pred_reshape = tf.image.resize(y_pred, (224, 224))\n",
        "\n",
        "    y_true_output = self.perc_model(y_true_reshape)\n",
        "    y_pred_output = self.perc_model(y_pred_reshape)\n",
        "\n",
        "    perceptual_loss = []\n",
        "\n",
        "    for idx, (y_true_layer, y_pred_layer) in enumerate(zip(y_true_output, y_pred_output)):\n",
        "      w, h, d = y_pred_layer[0].shape\n",
        "      perceptual_loss.append( (1/(w*h*d))*tf.reduce_mean( tf.square( y_true_layer - y_pred_layer ) ) )\n",
        "      #perceptual_loss.append( (1/(w*h*d))*tf.reduce_sum( tf.square( y_true_layer - y_pred_layer ) ) )\n",
        "\n",
        "    return self.lambda_mse*mse_loss + self.lambda_perc*tf.reduce_sum(perceptual_loss)\n",
        "\n",
        "\n",
        "\n",
        "loss_fn = MSE_Perceptual(params['perceptual_layers'], params['MSE_LOSS_LAMBDA'], params['PERP_LOSS_LAMBDA'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye-5OnB-uF3T"
      },
      "outputs": [],
      "source": [
        "def count_data_items(filenames):\n",
        "  n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "  return np.sum(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0zMJDkNt5Ir"
      },
      "outputs": [],
      "source": [
        "for grid_x, grid_y in grids:  \n",
        "  OUTPUT_PATH = '{}training_{}-{}_s1024/'.format(BASE_OUTPUT, grid_x, grid_y)\n",
        "\n",
        "  if params['USE_TFRECORD']:\n",
        "    GCS_PATH = '{}grid{}-{}_s1024'.format(BASE_DATA, grid_x, grid_y)\n",
        "    TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + \"/train*.tfrecord\")\n",
        "    VALID_FILENAMES = tf.io.gfile.glob(GCS_PATH + \"/val*.tfrecord\")\n",
        "\n",
        "    print(\"Number of train tfrecords: {}\".format(len(TRAINING_FILENAMES)))\n",
        "    print(\"Number of validation tfrecords: {}\".format(len(VALID_FILENAMES)))\n",
        "\n",
        "    NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "    NUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\n",
        "  else:\n",
        "    TRAINING_FILENAMES = glob(BASE_DATA + \"extracted/grid{}-{}_s1024/train/good/*.png\".format(grid_x, grid_y))\n",
        "    print(TRAINING_FILENAMES)\n",
        "\n",
        "    TRAINING_FILENAMES, VALID_FILENAMES, _, _ = train_test_split(TRAINING_FILENAMES, TRAINING_FILENAMES, test_size=0.1, random_state=100) ## Same split train/val in the TFRecords...\n",
        "    NUM_TRAINING_IMAGES = len(TRAINING_FILENAMES)\n",
        "    NUM_VALIDATION_IMAGES = len(VALID_FILENAMES)\n",
        "  \n",
        "  print(\"{} training images AND {} validation images\".format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES))\n",
        "\n",
        "  ae_model = get_cae()\n",
        "  output_folder = str(datetime.now()).replace(' ', '_').replace(':', '-')\n",
        "\n",
        "  if not os.path.exists(OUTPUT_PATH+output_folder):\n",
        "    os.makedirs(OUTPUT_PATH+output_folder)\n",
        "\n",
        "  config_file = open('{}{}/config_used.conf'.format(OUTPUT_PATH, output_folder),\"w+\")\n",
        "  for key in params:\n",
        "    config_file.write(\"{}={}\\n\".format(key, params[key]))\n",
        "  config_file.close()\n",
        "  \n",
        "  lr_callback2 = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n",
        "  cp = ModelCheckpoint(filepath='{}{}/best_model_val_loss.h5'.format(OUTPUT_PATH, output_folder), monitor='val_loss', save_best_only=True)\n",
        "\n",
        "  STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // params['BATCH_SIZE']\n",
        "  STEPS_PER_VAL = NUM_VALIDATION_IMAGES // params['BATCH_SIZE']\n",
        "\n",
        "  ae_model.compile(optimizer=\"adam\",\n",
        "                 loss=loss_fn,\n",
        "                 metrics=['mae', 'mse'])\n",
        "  \n",
        "  history = ae_model.fit(\n",
        "    get_train_dataset(TRAINING_FILENAMES, use_tfrecord=params['USE_TFRECORD']),\n",
        "    validation_data=get_validation_dataset(VALID_FILENAMES, use_tfrecord=params['USE_TFRECORD']),\n",
        "    epochs=params['EPOCHS'],\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    callbacks=[lr_callback2, cp],\n",
        "    validation_steps=STEPS_PER_VAL\n",
        "  )\n",
        "\n",
        "  \n",
        "  pd.DataFrame.from_dict(history.history).to_csv('{}{}/history.csv'.format(OUTPUT_PATH, output_folder),index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPrBPZNGDe5H"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Train_notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}