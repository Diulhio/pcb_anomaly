{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDaGq23pbF7I"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "!nvidia-smi\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, BatchNormalization, Input, Reshape, Flatten, Conv2DTranspose, MaxPooling2D, UpSampling2D, Add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LeakyReLU, Lambda, ReLU, Concatenate\n",
        "\n",
        "from functools import partial\n",
        "import re\n",
        "import numpy as np\n",
        "import math, os\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from datetime import datetime\n",
        "import random\n",
        "import cv2\n",
        "from glob import glob\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import PrecisionRecallDisplay\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqB-6EBsBNjG"
      },
      "outputs": [],
      "source": [
        "!pip3 install cmapy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBaF5rPSb2wB"
      },
      "source": [
        "# Parameters definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdEBeb7ZbXYt"
      },
      "outputs": [],
      "source": [
        "BASE_GCS = 'gs://pcbs_thomas/grids/'\n",
        "BASE_DATA = '/content/gdrive/MyDrive/mpi_pcbs/'\n",
        "\n",
        "## \n",
        "edge_x = [0, 24]\n",
        "edge_y = [0, 14]\n",
        "\n",
        "grid_list = [ [16,0], [24,0], [8,7], [16,7], [8,14], [24,14] ]\n",
        "#grid_list = [ [16,7] ]\n",
        "\n",
        "params = {\n",
        "  'use_layer' : 12, #Layers: 5, 10, 15, 20 -> Melhor atÃ© agora: 12\n",
        "  'BATCH_SIZE' : 128,\n",
        "  'RECORD_SIZE' : (256+20,256+20,3),\n",
        "  'IMAGE_SIZE' : (256,256,3),\n",
        "  'LATENT_DIM' : 500,\n",
        "\n",
        "  'SEED' : 100,\n",
        "\n",
        "  'use_bn' : True,\n",
        "  'use_bn_dconv' : True,\n",
        "  'lrelu_slop' : 0.2,\n",
        "\n",
        "  'use_tpu' : True,\n",
        "\n",
        "  'USE_TFRECORD' : False\n",
        "}\n",
        "\n",
        "def get_last_model(BASE_PATH):\n",
        "  all_dir = sorted(glob(BASE_PATH + \"*/\"))\n",
        "  return all_dir[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvN9LAm5btTS"
      },
      "source": [
        "# Initialization of TPUs "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ed7W4EZPdj9Z"
      },
      "outputs": [],
      "source": [
        "# Detect TPU, return appropriate distribution strategy\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu is not None:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy() \n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li3gnhW6boza"
      },
      "source": [
        "# Defining the model and load the weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2bpJ7Nmbl5D"
      },
      "outputs": [],
      "source": [
        "def conv_block(x, filters=16, kernel=5, stride=2, transpose=False, leaky=True, slope=0.2, padding='same', bn=False, bias=True, only_conv=False):\n",
        "  conv = Conv2DTranspose if transpose else Conv2D\n",
        "  activation = LeakyReLU(slope) if leaky else ReLU()\n",
        "  \n",
        "  x = conv(filters=filters, kernel_size=(kernel,kernel), strides=stride, padding=padding, use_bias=bias)(x)\n",
        "  if not only_conv:\n",
        "    if bn:\n",
        "      x = BatchNormalization()(x)\n",
        "    x = activation(x)\n",
        "  \n",
        "  return x\n",
        "\n",
        "def get_cae():\n",
        "  with strategy.scope():\n",
        "    n_leves_enc = 7\n",
        "    n_dense = int(params['IMAGE_SIZE'][0]/(2**n_leves_enc))\n",
        "\n",
        "    inputs = Input(shape=params['IMAGE_SIZE'], name='encoder_input')\n",
        "    conv1 = conv_block(inputs, 32, bn=params['use_bn'], slope=params['lrelu_slop'])\n",
        "    conv2 = conv_block(conv1, 64, bn=params['use_bn'], slope=params['lrelu_slop'])  \n",
        "    conv3 = conv_block(conv2, 128, bn=params['use_bn'], slope=params['lrelu_slop'])  \n",
        "    conv4 = conv_block(conv3, 128, bn=params['use_bn'], slope=params['lrelu_slop'])   \n",
        "    conv5 = conv_block(conv4, 256, bn=params['use_bn'], slope=params['lrelu_slop'])   \n",
        "    conv6 = conv_block(conv5, 256, bn=params['use_bn'], slope=params['lrelu_slop'])  \n",
        "    conv7 = conv_block(conv6, 256, bn=params['use_bn'], slope=params['lrelu_slop']) \n",
        "\n",
        "    conv7_flat = Flatten()(conv7)\n",
        "    fc1 = Dense(units=(n_dense*n_dense*256))(conv7_flat)\n",
        "    if params['use_bn']:\n",
        "      fc1 = BatchNormalization()(fc1)\n",
        "    fc1 = LeakyReLU(alpha=params['lrelu_slop'])(fc1)\n",
        "\n",
        "    fc1 = Dense(units=params['LATENT_DIM'])(fc1)\n",
        "    fc1 = LeakyReLU(alpha=params['lrelu_slop'])(fc1)\n",
        "\n",
        "    fc2 = Dense(units=(n_dense*n_dense*256))(fc1)\n",
        "    if params['use_bn']:\n",
        "      fc2 = BatchNormalization()(fc2)\n",
        "    fc2 = LeakyReLU(alpha=params['lrelu_slop'])(fc2)\n",
        "    \n",
        "    z_mat = Reshape((n_dense,n_dense,256))(fc2)\n",
        "    dconv0 = conv_block(z_mat, 256, transpose=True, bn=params['use_bn_dconv'], slope=params['lrelu_slop'])\n",
        "    dconv1 = conv_block(dconv0, 256, transpose=True, bn=params['use_bn_dconv'], slope=params['lrelu_slop'])\n",
        "    dconv2 = conv_block(dconv1, 128, transpose=True, bn=params['use_bn_dconv'], slope=params['lrelu_slop'])\n",
        "    dconv3 = conv_block(dconv2, 128, transpose=True, bn=params['use_bn_dconv'], slope=params['lrelu_slop'])\n",
        "    dconv4 = conv_block(dconv3, 64, transpose=True, bn=params['use_bn_dconv'], slope=params['lrelu_slop'])\n",
        "    dconv5 = conv_block(dconv4, 32, transpose=True, bn=params['use_bn_dconv'], slope=params['lrelu_slop'])\n",
        "    \n",
        "\n",
        "    dconv6 = Conv2DTranspose(filters=params['IMAGE_SIZE'][2], kernel_size=(5,5), strides=2, padding='same', \n",
        "        use_bias=True, activation='sigmoid')(dconv5)\n",
        "\n",
        "    ae_model = Model(inputs, dconv6, name=\"ae\")\n",
        "    #ae_model.summary()\n",
        "  return ae_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH4Pujbmbgzb"
      },
      "source": [
        "# Creating the TF.datasets with Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EahO0nLTeKor"
      },
      "outputs": [],
      "source": [
        "def decode_image(image):\n",
        "  image = tf.image.decode_jpeg( image, channels=params['RECORD_SIZE'][2] )\n",
        "  image = tf.cast(image, tf.float32) / 255.0\n",
        "\n",
        "  image = tf.reshape(image, [*params['RECORD_SIZE']])\n",
        "  return image\n",
        "\n",
        "def decode_mask(image):\n",
        "  image = tf.image.decode_jpeg( image, channels=1 )\n",
        "  image = tf.cast(image, tf.float32) / 255.0\n",
        "\n",
        "  image = tf.reshape(image, [params['RECORD_SIZE'][0], params['RECORD_SIZE'][1], 1])\n",
        "  return image\n",
        "\n",
        "def read_tfrecord(example):\n",
        "  feature = {'image':tf.io.FixedLenFeature([], tf.string),\n",
        "              'mask1': tf.io.FixedLenFeature([], tf.string),\n",
        "              'mask2': tf.io.FixedLenFeature([], tf.string),\n",
        "              'image_name': tf.io.FixedLenFeature([], tf.string)\n",
        "            }\n",
        "\n",
        "  example = tf.io.parse_single_example(example, feature)\n",
        "  image = decode_image(example['image'])\n",
        "  mask1 = decode_mask(example['mask1'])\n",
        "  mask2 = decode_mask(example['mask2'])\n",
        "  name = example['image_name']\n",
        "  name = tf.cast(name, tf.string)\n",
        "\n",
        "  return image, mask1, mask2\n",
        "\n",
        "def get_all_cropped(image, mask1, mask2):\n",
        "  init_x = 10\n",
        "  init_y = 10\n",
        "  if grid_x == edge_x[0]:\n",
        "    init_x = 0\n",
        "  else:\n",
        "    init_x = 10\n",
        "\n",
        "  if grid_y == edge_y[0]:\n",
        "    init_y = 0\n",
        "  else:\n",
        "    init_y = 10\n",
        "  return tf.image.crop_to_bounding_box(image, init_x, init_y, 256, 256), tf.image.crop_to_bounding_box(mask1, init_x, init_y, 256, 256), tf.image.crop_to_bounding_box(mask2, init_x, init_y, 256, 256)\n",
        "\n",
        "def read_image(img_path, channels=3):\n",
        "  img = tf.io.read_file(img_path)\n",
        "  img = tf.image.decode_image(img, channels=channels)\n",
        "  if channels == 1:\n",
        "    img = 255-img\n",
        "  img = tf.cast(img, tf.float32) / 255.0\n",
        "\n",
        "  return img\n",
        "\n",
        "def read_image_and_mask(img_path):\n",
        "  input_img = read_image(img_path)\n",
        "\n",
        "  if not tf.strings.regex_full_match(img_path, \"[\\w/.-]*good{1}[\\w/.-]*\"):\n",
        "    tmp_img_path = tf.strings.regex_replace(img_path, '/test/', '/ground_truth/')\n",
        "    mask1_img_path = tf.strings.regex_replace(tmp_img_path, '.png', '_mask.png')\n",
        "    mask1 = mask2 = read_image(mask1_img_path, 1)\n",
        "  else:\n",
        "    mask1 = mask2 = read_image('./blank_image.png', 1)\n",
        "    #mask1 = mask2 = tf.cast( 255*tf.ones( tf.shape(input_img)[:-1] ), tf.float32 ) / 255.0\n",
        "\n",
        "    #mask1 = tf.reshape(mask1, [params['IMAGE_SIZE'][0], params['IMAGE_SIZE'][1], 1])\n",
        "    #mask2 = tf.reshape(mask1, [params['IMAGE_SIZE'][0], params['IMAGE_SIZE'][1], 1])\n",
        "    #mask1 = mask2 = tf.zeros(tf.shape(input_img)[:-1])\n",
        "\n",
        "  return input_img, mask1, mask2\n",
        "\n",
        "def load_dataset(filenames, use_tfrecord=True, ordered=False):\n",
        "  ignore_order = tf.data.Options()\n",
        "  if not ordered:\n",
        "    ignore_order.experimental_deterministic = False\n",
        "\n",
        "  if use_tfrecord:\n",
        "    print(\"Reading from tfrecord!\")\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "    dataset = dataset.with_options(ignore_order)\n",
        "    dataset = dataset.map(partial(read_tfrecord), num_parallel_calls=AUTO)\n",
        "  else:\n",
        "    img_blank = np.zeros((params['IMAGE_SIZE'][1],params['IMAGE_SIZE'][0],3), np.uint8)\n",
        "    cv2.imwrite(\"./blank_image.png\", img_blank)    \n",
        "    print(\"Reading from file list!\")\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
        "    dataset = dataset.with_options(ignore_order)\n",
        "    dataset = dataset.map(partial(read_image_and_mask), num_parallel_calls=AUTO)\n",
        "\n",
        "  return dataset\n",
        "\n",
        "def get_test_dataset(filenames, use_tfrecord=True):\n",
        "  dataset = load_dataset(filenames, use_tfrecord=use_tfrecord)\n",
        "  #dataset = dataset.shuffle(2048, seed=params['SEED'])\n",
        "  dataset = dataset.batch(params['BATCH_SIZE'])\n",
        "  if use_tfrecord:\n",
        "    dataset = dataset.map(lambda image, mask1, mask2: get_all_cropped(image, mask1,mask2), num_parallel_calls=AUTO )\n",
        "  dataset = dataset.cache()\n",
        "  dataset = dataset.prefetch(AUTO)\n",
        "  return dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LShDE7HmbWdq"
      },
      "source": [
        "#Prediction and perceptual difference\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xt14kPmxyZ2u"
      },
      "outputs": [],
      "source": [
        "def predict_perpdiff(ds_imgs, model):\n",
        "  print(\"Prediction...\")\n",
        "  perp_model = tf.keras.applications.VGG19(input_shape=(224,224,3))\n",
        "  modelOutputs = [ perp_model.layers[i].output for i in [params['use_layer']] ]\n",
        "  perp_model = Model(perp_model.inputs, modelOutputs)\n",
        "\n",
        "\n",
        "  for ds_imgs in test_dataset.take(1):\n",
        "    input_imgs = ds_imgs[0].numpy()\n",
        "\n",
        "    ## Predict the reconstructed image\n",
        "    y_pred = model.predict(input_imgs)  \n",
        "\n",
        "    ## Resize the images to the input size of VGG19\n",
        "    y_true_reshape = tf.image.resize(input_imgs, (224, 224))\n",
        "    y_pred_reshape = tf.image.resize(y_pred, (224, 224))\n",
        "    mask1_reshape = tf.image.resize(ds_imgs[1], (224, 224))\n",
        "    mask2_reshape = tf.image.resize(ds_imgs[2], (224, 224))\n",
        "\n",
        "    ## Pass all images in the VGG19 and get the perceptual layers outputs\n",
        "    perp_input = perp_model([y_true_reshape])\n",
        "    perp_pred = perp_model([y_pred_reshape])\n",
        "\n",
        "  return y_true_reshape, y_pred_reshape, perp_input, perp_pred, mask2_reshape, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqByNDNUytsw"
      },
      "outputs": [],
      "source": [
        "def compute_min_max(perp_input, perp_pred):\n",
        "  print(\"Computing min and max...\")\n",
        "  max_norm = 0\n",
        "  min_norm = 1000000\n",
        "\n",
        "  for img_idx in range(perp_input.shape[0]):\n",
        "    perp_img = tf.math.abs( perp_input[img_idx,:,:,0] - perp_pred[img_idx,:,:,0] )\n",
        "    \n",
        "    for i in range(1, perp_input.shape[3] ):\n",
        "      perp_img += tf.math.abs( perp_input[img_idx,:,:,i] - perp_pred[img_idx,:,:,i] )\n",
        "      max_value = tf.math.reduce_max(perp_img)\n",
        "      min_value = tf.math.reduce_min(perp_img)\n",
        "\n",
        "      if max_value > max_norm:\n",
        "        max_norm = max_value\n",
        "      if min_value < min_norm:\n",
        "        min_norm = min_value\n",
        "\n",
        "  print(\"max_norm: {}\".format(max_norm))\n",
        "  print(\"min_norm: {}\".format(min_norm))\n",
        "\n",
        "  return min_norm, max_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-DpeUWey2Mk"
      },
      "outputs": [],
      "source": [
        "def calculate_anomaly_map(perp_input, perp_pred, min_norm, max_norm):\n",
        "  y_pred_all = []\n",
        "  all_perp = []\n",
        "\n",
        "  print(\"Calculating anomaly map\")\n",
        "  for img_idx in range(perp_input.shape[0]):\n",
        "      perp_img = tf.math.abs( perp_input[img_idx,:,:,0] - perp_pred[img_idx,:,:,0] )\n",
        "      for i in range(1, perp_input.shape[3] ):\n",
        "        perp_img += tf.math.abs( perp_input[img_idx,:,:,i] - perp_pred[img_idx,:,:,i] )\n",
        "\n",
        "      perp_img =(perp_img - min_norm) / (max_norm - min_norm)      \n",
        "\n",
        "      perp_img = tf.image.resize(tf.expand_dims(perp_img, axis=2), (224,224))\n",
        "      perp_img = tf.squeeze(perp_img)\n",
        "\n",
        "      all_perp.append(perp_img)\n",
        "      y_pred_all.append( perp_img.numpy().ravel() )\n",
        "  \n",
        "  return all_perp, y_pred_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KV25sLqy-m7"
      },
      "outputs": [],
      "source": [
        "def process_mask(mask_arr, min_pixel_classification=10):\n",
        "  mask_invert = 1-mask_arr\n",
        "  ## Generate classification labels\n",
        "  mask_classification = np.array([np.sum(n) > min_pixel_classification for n in mask_invert])\n",
        "  ## Adjust segmentation labels\n",
        "  mask_invert = tf.reshape(mask_invert, [-1])\n",
        "  mask_invert = mask_invert.numpy().astype(bool)\n",
        "\n",
        "  return mask_classification, mask_invert\n",
        "\n",
        "def generate_seg_auc(y_pred, mask):\n",
        "  print(\"Ploting ROC AUC\") \n",
        "  \n",
        "  fpr, tpr, thresholds = roc_curve(mask, np.array(y_pred).ravel())\n",
        "  roc_auc = auc(fpr,tpr)\n",
        "\n",
        "  gmeans = np.sqrt(tpr * (1-fpr))\n",
        "  ix = np.argmax(gmeans)\n",
        "  th_max_rocauc = thresholds[ix]\n",
        "  print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
        "\n",
        "  fig, ax = plt.subplots(1,1)\n",
        "  ax.plot(fpr, tpr, label='ROC curve (area = %0.4f)' % roc_auc)\n",
        "  ax.plot([0, 1], [0, 1], 'k--')\n",
        "  ax.set_xlim([0.0, 1.0])\n",
        "  ax.set_ylim([0.0, 1.05])\n",
        "  ax.set_xlabel('False Positive Rate')\n",
        "  ax.set_ylabel('True Positive Rate')\n",
        "  ax.set_title('Segmentation ROC-AUC')\n",
        "  ax.legend(loc=\"lower right\")\n",
        "\n",
        "  return fpr, tpr, roc_auc, th_max_rocauc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TzEaM1YzNHO"
      },
      "outputs": [],
      "source": [
        "def get_other_metrics(y_pred, mask, class_labels, th_step = 0.01, min_pixel_classification=10):\n",
        "\n",
        "  print(\"Calculating IoU, detection ROC-AUC, F1-Score, Recall and Precision\")\n",
        "  all_iou = []\n",
        "  \n",
        "  all_precision = []\n",
        "  all_recall = []\n",
        "  all_f1 = []\n",
        "\n",
        "  d_fpr = []\n",
        "  d_tpr = []\n",
        "\n",
        "  d_precision = []\n",
        "  d_recall = []\n",
        "  d_f1_score = []\n",
        "  \n",
        "  th = 1.0\n",
        "  while th >= 0.0:\n",
        "    ### IoU ###\n",
        "    y_preds = np.array(y_pred).ravel() > th\n",
        "    y_preds = y_preds.astype(bool)\n",
        "    tn, fp, fn, tp = confusion_matrix(mask, y_preds).ravel()\n",
        "    \n",
        "    iou = tp/(tp + fn + fp)\n",
        "    all_iou.append(iou)\n",
        "\n",
        "    ### Detection ###\n",
        "    y_preds_class = np.array(y_pred) > th\n",
        "    y_preds_class = np.array([np.sum(n) > min_pixel_classification for n in y_preds_class])\n",
        "\n",
        "    tnd, fpd, fnd, tpd = confusion_matrix(class_labels, y_preds_class).ravel()\n",
        "    fpr_detec = fpd / (fpd+tnd)\n",
        "    tpr_detec = tpd / (tpd+fnd)\n",
        "    d_fpr.append(fpr_detec)\n",
        "    d_tpr.append(tpr_detec)\n",
        "    th -= th_step\n",
        "\n",
        "    ## Precision ##\n",
        "    s_prec = precision_score(mask, y_preds, zero_division=0)\n",
        "    d_prec = precision_score(class_labels, y_preds_class, zero_division=0)\n",
        "    all_precision.append(s_prec)\n",
        "    d_precision.append(d_prec)\n",
        "\n",
        "    ## Recall ##\n",
        "    s_rec = recall_score(mask, y_preds)\n",
        "    d_rec = recall_score(class_labels, y_preds_class)\n",
        "    all_recall.append(s_rec)\n",
        "    d_recall.append(d_rec)\n",
        "\n",
        "    ## F1-Score ##\n",
        "    s_f1 = f1_score(mask, y_preds)\n",
        "    d_f1 = f1_score(class_labels, y_preds_class)\n",
        "    all_f1.append(s_f1)\n",
        "    d_f1_score.append(d_f1)\n",
        "\n",
        "  ##########################\n",
        "  ## Showing some results ##\n",
        "  ##########################\n",
        "  max_iou = max(all_iou)\n",
        "  th_max_iou = 1-np.argmax(all_iou)*th_step\n",
        "  pos_max_iou = np.argmax(all_iou)\n",
        "  print(\"Max IoU: {:.4f} -> {:.4f}\".format(max_iou,  th_max_iou))\n",
        "  print(\"Precision, Recall, F1-Score in max IoU TH: {:.2f}, {:.2f}, {:.2f}\".format(all_precision[pos_max_iou], all_recall[pos_max_iou], all_f1[pos_max_iou]))\n",
        "\n",
        "  max_precision = np.max(all_precision)\n",
        "  max_recall = np.max(all_recall)\n",
        "  max_f1 = np.max(all_f1)\n",
        "\n",
        "  print(\"Max Precision, Recall, F1: {:.2f}, {:.2f}, {:.2f}\".format(max_precision, max_recall, max_f1))\n",
        "\n",
        "  ##########################\n",
        "  ## Generating the curve ##\n",
        "  ##########################\n",
        "  d_roc_auc = auc(d_fpr, d_tpr)\n",
        "  fig, ax = plt.subplots(1,1)\n",
        "  ax.plot(d_fpr, d_tpr, label='ROC curve (area = %0.4f)' % d_roc_auc)\n",
        "  ax.plot([0, 1], [0, 1], 'k--')\n",
        "  ax.set_xlim([0.0, 1.0])\n",
        "  ax.set_ylim([0.0, 1.05])\n",
        "  ax.set_xlabel('False Positive Rate')\n",
        "  ax.set_ylabel('True Positive Rate')\n",
        "  ax.set_title('Detection ROC-AUC')\n",
        "  ax.legend(loc=\"lower right\")\n",
        "\n",
        "  return d_fpr, d_tpr, d_roc_auc, all_precision, d_precision, all_recall, d_recall, all_f1, d_f1_score, all_iou, max_iou, th_max_iou\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcdPiDXZHuBc"
      },
      "outputs": [],
      "source": [
        "for grid_x, grid_y in grid_list:\n",
        "  ## Get model weights\n",
        "  MODEL_PATH_BASE = '/content/gdrive/MyDrive/pcbs_cae/training_{}-{}_s1024/'.format(grid_x, grid_y)\n",
        "  \n",
        "  MODEL_PATH = get_last_model(MODEL_PATH_BASE)\n",
        "  model = get_cae()\n",
        "  model.load_weights(MODEL_PATH + 'best_model_val_loss.h5')\n",
        "\n",
        "  # Loading data...\n",
        "  if params['USE_TFRECORD']:\n",
        "    GCS_PATH = '{}grid{}-{}_s1024'.format(BASE_GCS, grid_x, grid_y)\n",
        "    TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + \"/test*.tfrecord\")\n",
        "    test_dataset = get_test_dataset(TEST_FILENAMES)\n",
        "  else:\n",
        "    TEST_FILENAMES = glob(BASE_DATA + \"extracted/grid{}-{}_s1024/test/*/*.png\".format(grid_x, grid_y))\n",
        "    test_dataset = get_test_dataset(TEST_FILENAMES, False)\n",
        "\n",
        "  # Predict all images\n",
        "  y_true_reshape, y_pred_reshape, perp_input, perp_pred, mask2_reshape, y_pred = predict_perpdiff(test_dataset, model)\n",
        "  \n",
        "  # Get min max for normalization\n",
        "  min_norm, max_norm = compute_min_max(perp_input, perp_pred)\n",
        "\n",
        "  # Calculate perceptual anomaly map\n",
        "  all_perp, y_pred_all = calculate_anomaly_map(perp_input, perp_pred, min_norm, max_norm)\n",
        "\n",
        "  # Generate and show metrics\n",
        "  mask2_classification, mask2_invert = process_mask(mask2_reshape)\n",
        "  fpr, tpr, roc_auc, th_max_rocauc = generate_seg_auc(y_pred_all, mask2_invert)\n",
        "  d_fpr, d_tpr, d_roc_auc, all_precision, d_precision, all_recall, d_recall, all_f1, d_f1_score, all_iou, max_iou, th_max_iou = get_other_metrics(y_pred_all, mask2_invert, mask2_classification)\n",
        "\n",
        "  # Save the metrics results\n",
        "  with open(MODEL_PATH_BASE + 'mask2_data.npy', 'wb') as f:\n",
        "    ## Saving roc_curve data for future plot\n",
        "    np.save(f, fpr)\n",
        "    np.save(f, tpr)\n",
        "    np.save(f, np.array([roc_auc]))\n",
        "    ## Saving IoU\n",
        "    np.save(f, np.array(all_iou))\n",
        "    np.save(f, np.array([max_iou, th_max_iou]))\n",
        "    ## Saving detection ROC AUC\n",
        "    np.save(f, d_fpr)\n",
        "    np.save(f, d_tpr)\n",
        "    np.save(f, np.array([d_roc_auc]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maT7-YYn8cIv"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Test_notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}